---
title: Introduction
bibliography: references.bib
---

::: justify
## Background

In the effort to understand the brain and its function, connectomics (the mapping of neural wiring diagrams in precise detail, often via electron microscopy) has proven a useful tool. Connectomes are now available for entire larval [@winding2023] and adult fly brains [@schlegel2023; @dorkenwald2023], large regions of mouse visual cortex [@microns2021], human cortex [@shapson-coe2021], and many others. These reconstructions now contain on the order of 100,000s of neurons, and 100s of millions of synapses. This dramatic scaling in accurate connnectome reconstruction has been enabled by a strategy of scalable automatic segmentation of neurons and detection of synapses, followed by laborious human proofreading to correct false merges and extend incomplete pieces of neurons. This effort has been done, understandably, with the intent that we want to be able to trust the resulting reconstruction and believe that it is a fair representation of the neuroanatomy and connectivity of the biological sample.

## The question

However, since this manual proofreading is laborious (for instance, there were [2.7 million edits in FlyWire over 4 years](https://x.com/FlyWireNews/status/1674886396564193281?s=20) as of June 2023) it is worth reflecting on the scientific value of this effort. **How consequential was this proofreading on the downstream measures we care about for analysis, such as connection probabilities between cell types? Are some connectivity features stable with proofreading, and others variable? Are certain edits more important than others, in terms of their impact on overal circuit structure?** Next, we touch on how others have explored these and related questions in prior work, before motivating our own contributions here.

## Prior work

1.  paper from carey and jovo on power

In @priebe2013, the authors ask whether one should desire lots of "highly proofread" data, or a smaller amount of partially proofread or noisy data. They frame this question from the perspective of statistical hypothesis testing, asking which approach has higher power for distinguishing network parameters under a toy model. This work is an illustrative case for why, at least in theory, it is possible to actually *prefer* lots of unproofread data to a smaller amount of curated data. This is a prospect worth considering, especially in light of costly proofreading endeavors. However, in this work the toy model was set up such that unproofread data had no *bias*, but merely represented a noisier version of a ground truth network. In reality, the unproofread networks we observe in connectomics likely have extreme bias in the way that errors are observed. For instance, one error in segmentation could lead to missing the entire primary axon of a neuron, effectively deleting all of that neurons outputs in one stroke.

1.  casey paper

2.  phillip paper mentions variability

## Why it matters

There are several reasons why understanding the variability of connectivity with respect to proofreading is worthwhile for modern connectomics:

First, understanding the sensitivity of connectivity features to proofreading provides clues as to the technical variability associated with an imperfect reconstruction of an underlying biological network. For instance, if one wanted to compare connectivity feature `Y` between two datasets, but `Y` varies drastically based on proofreading level, then it will be challenging to compare `Y` without ensuring proofreading was done in the exact same way for these two datasets.

Second, understanding this sensitivity is important for directing future proofreading efforts. Achieving a "perfect connectome" reconstruction is a comforting goal to strive for, but given finite time and resources, it is worthwhile to consider which efforts will actually affect downstream analysis we are interested in. Increasingly, a single connectomics datasets may be used for addressing many questions by directing proofreading toward particular sub-goals. It is worth understanding which questions can be answered "out-of-the-box" with no additional proofreading after the initial segmentation, and which will require further effort to get a trustworth answer.

## Our contribution

In this work, we investigate these questions using large-scale reconstructions of mouse visual cortex as testbeds for these ideas. We *do not* aim to answer these questions holistically for all connectomics datasets and possible connectivity features; such an endeavor would be impossible since the answer is likely to depend greatly on the dataset and the question. Rather, we provide a set of guiding principles for which types of features are likely to be variable, and provide tools for other connectomicists to analyze these questions on their own data.
:::