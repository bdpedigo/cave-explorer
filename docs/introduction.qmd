---
title: Introduction
bibliography: references.bib
toc: true
cap-location: margin
---

::: {.justify}

## Background

In the effort to understand the brain and its function, connectomics has proven a useful tool. [*Connectome*: a map of neural wiring diagrams in precise detail, often obtained via electron microscopy followed by manual or automated reconstruction of the neurons and other cells in that image volume.]{.aside} *Connectomes* are now available for entire larval [@winding2023] and adult fly brains [@schlegel2023; @dorkenwald2023], large regions of mouse visual cortex [@microns2021], human cortex [@shapson-coe2021], and many other areas and organisms. The largest of these connectome reconstructions now contain on the order of hundreds of thousands of neurons, and hundreds of millions of synapses. This unprecedented scale in connnectome reconstruction has been enabled by segmenting cells and annotating synapses with computer vision, followed by laborious human proofreading to correct false merges and extend incomplete pieces of neurons. This latter effort has been done, understandably, with the intent that we want to be able to trust the resulting reconstruction and believe that it is a fair representation of the neuroanatomy and connectivity of the biological sample: thus, one should correct the results of an automated algorithm by this manual proofreading process.


## The questions

However, since this manual proofreading is laborious (for instance, there were [2.7 million edits in FlyWire over 4 years](https://x.com/FlyWireNews/status/1674886396564193281?s=20) as of June 2023) it is worth reflecting on the scientific value of this effort. **How consequential was this proofreading on the downstream measures we care about for analysis,** such as connection probabilities between cell types**? Are some connectivity features stable with proofreading, and others variable? Are certain edits more important than others**, in terms of their impact on overal circuit structure? Next, we touch on how others have explored these and related questions in prior work, before motivating our own contributions here.

## Prior work

In @priebe2013, the authors ask whether one should desire lots of "highly proofread" data, or a smaller amount of partially proofread or noisy data. They frame this question from the perspective of statistical hypothesis testing, asking which approach has higher power for distinguishing network parameters under a toy model. This work is an illustrative case for why, at least in theory, it is possible to actually *prefer* lots of unproofread data to a smaller amount of curated data. This is a prospect worth considering, especially in light of costly proofreading endeavors. However, this work was done in a toy model which was set up such that unproofread data had no *bias*, but merely represented a noisier version of a ground truth network. [*Bias:* the distance between an expected value of an estimator and the true value of the parameter it is trying to estimate.]{.aside} In reality, the unproofread networks we observe in connectomics likely have extreme bias in the way that errors are observed. For instance, one error in segmentation could lead to missing the entire primary axon of a neuron, effectively deleting all of that neurons outputs in one stroke. In this work, we consider how connectivity estimands

![Text describing the key result from @priebe2013. In essence, power is greater in their toy example when tracing more edges with more errors.](./images/priebe-comparison.png)

This question of technical variability and proofreading tangentially arose in @schlegel2023 as the authors examined a comparison of two fly connectomes: [FlyWire](https://flywire.ai/) and [Hemibrain](https://www.janelia.org/project-team/flyem/hemibrain). The authors were interested in quantitative comparisons of connectivity between cell types that were cross-matched between the left and right hemispheres of the FlyWire connectome and the single hemisphere Hemibrain connectome. They found a general agreement in cell-type-to-cell-type connections both within (FlyWire-left:FlyWire-right) and between (FlyWire:Hemibrain) datasets; still, they wondered how much technical differences in reconstruction between these reconstructions could explain the differences they saw. The authors created synthetic datasets by 

-   casey quantitative neuroanatomy paper


## Why it matters

There are several reasons why understanding the variability of connectivity with respect to proofreading is worthwhile for modern connectomics:

First, understanding the sensitivity of connectivity features to proofreading provides clues as to the technical variability associated with an imperfect reconstruction of an underlying biological network. For instance, if one wanted to compare connectivity feature $Y$ between two datasets, but $Y$ varies drastically based on proofreading level, then it will be challenging to compare $Y$ without ensuring proofreading was done in the exact same way for these two datasets.

Second, understanding this sensitivity is important for directing future proofreading efforts. Achieving a "perfect connectome" reconstruction is a comforting goal to strive for, but given finite time and resources, it is worthwhile to consider which efforts will actually affect downstream analysis we are interested in. Increasingly, a single connectomics datasets may be used for addressing many questions by directing proofreading toward particular sub-goals. It is worth understanding which questions can be answered "out-of-the-box" with no additional proofreading after the initial segmentation, and which will require further effort to get a trustworth answer.

## Our contribution

In this work, we investigate these questions using large-scale reconstructions of mouse visual cortex as testbeds for these ideas. We *do not* aim to answer these questions holistically for all connectomics datasets and possible connectivity features; such an endeavor would be impossible since the answer is likely to depend greatly on the dataset and the question. Rather, we provide a set of guiding principles for which types of features are likely to be variable, and provide tools for other connectomicists to analyze these questions on their own data.

## Outline

We start by clearly defining a set of connectivity features to consider for this work.

Then, we extract the complete set of proofreading edits performed on a highly curated column of cortical connectivity in a mouse's visual cortex. We also map each synapse between neurons in this column to the edits it "depends" on, in the sense that those edits had to happen for a statement about soma $i$ to soma $j$ connectivity to be made.

Using this information, we then construct various "sloppy" networks, instantiated by replaying particular edits over the network and omitting others. These networks vary in their degree of completeness (i.e. some measure of how many of the edits were used) from the original segmentation all the way to the final proofread dataset. We also vary the "proofreader model" used to assign edits to "ON" or "OFF" in some ordering (i.e. whether edits are replayed uniformly at random, in the order they happened, in order of euclidean distance from the soma, etc.).

:::