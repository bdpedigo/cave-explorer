---
title: Introduction
bibliography: references.bib
---

::: justify
## Background

In the effort to understand the brain and its function, connectomics (the mapping of neural wiring diagrams in precise detail, often via electron microscopy) has proven a useful tool. Connectomes are now available for entire larval [@winding2023] and adult fly brains [@schlegel2023; @dorkenwald2023], large regions of mouse visual cortex [@microns2021], human cortex [@shapson-coe2021], and many others. These reconstructions now contain on the order of 100,000s of neurons, and 100s of millions of synapses. This dramatic scaling in accurate connnectome reconstruction has been enabled by a strategy of scalable automatic segmentation of neurons and detection of synapses, followed by laborious human proofreading to correct false merges and extend incomplete pieces of neurons. This effort has been done, understandably, with the intent that we want to be able to trust the resulting reconstruction and believe that it is a fair representation of the neuroanatomy and connectivity of the biological sample.

## The question

However, since this manual proofreading is laborious (for instance, there were [2.7 million edits in FlyWire over 4 years](https://x.com/FlyWireNews/status/1674886396564193281?s=20) as of June 2023) it is worth reflecting on the scientific value of this effort. **How consequential was this proofreading on the downstream measures we care about for analysis, such as connection probabilities between cell types? Are some connectivity features stable with proofreading, and others variable? Are certain edits more important than others, in terms of their impact on overal circuit structure?** Next, we touch on how others have explored these and related questions in prior work, before motivating our own contributions here.

## Prior work

1.  paper from carey and jovo on power

In @priebe2013, the authors ask whether one should desire lots of "highly proofread" data, or a smaller amount of partially proofread or noisy data. They frame this question from the perspective of statistical hypothesis testing, asking which approach has higher power for distinguishing network parameters under a toy model. This work is an illustrative case for why, at least in theory, it is possible to actually *prefer* lots of unproofread data to a smaller amount of curated data. This is a prospect worth considering, especially in light of costly proofreading endeavors. However, in this work the toy model was set up such that unproofread data had no *bias*, but merely represented a noisier version of a ground truth network. In reality, the unproofread networks we observe in connectomics likely have extreme bias in the way that errors are observed. For instance, one error in segmentation could lead to missing the entire primary axon of a neuron, effectively deleting all of that neurons outputs in one stroke.

1.  casey paper

2.  phillip paper mentions variability

## Why it matters

1.  understand what we can trust about the data we have

1.  understand how to direct future efforts of proofreading
2.  understand

## Our contribution
:::